{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\npython3 extract.py <doclist>\\n\\nTEXT:filename identifier\\nACQUIRED:entities that were acquired\\nACQBUS:the business focus of the acquired entities\\nACQLOC:the location of the acquired entities\\nDLRAMT:the amount paid for the acquired entities\\nPURCHASER:entities that purchased the acquired entities\\nSELLER:entities that sold the acquired entities\\nSTATUS:status description of the acquisition event\\n'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from __future__ import unicode_literals, print_function\n",
    "import pandas as pd\n",
    "import sys\n",
    "from spacy.lang.en import English\n",
    "from featureExtract import extractFeatures\n",
    "\n",
    "nlp = English()\n",
    "nlp.add_pipe('sentencizer')\n",
    "\n",
    "\"\"\"\n",
    "python3 extract.py <doclist>\n",
    "\n",
    "TEXT:filename identifier\n",
    "ACQUIRED:entities that were acquired\n",
    "ACQBUS:the business focus of the acquired entities\n",
    "ACQLOC:the location of the acquired entities\n",
    "DLRAMT:the amount paid for the acquired entities\n",
    "PURCHASER:entities that purchased the acquired entities\n",
    "SELLER:entities that sold the acquired entities\n",
    "STATUS:status description of the acquisition event\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in training data\n",
    "docFeats = [\"path\", \"filename\", \"text\"]\n",
    "\n",
    "docsInfo = []\n",
    "dataFolder = 'data/development-docs'\n",
    "dataNames = os.listdir(dataFolder)\n",
    "for dataName in dataNames:\n",
    "    dcInf = []\n",
    "    dcInf.append(dataFolder)\n",
    "    dcInf.append(dataName)\n",
    "    with open(os.path.join(dataFolder, dataName), 'r') as f:\n",
    "        txt = \"\"\n",
    "        for l in f.readlines():\n",
    "            txt += l.strip()\n",
    "        dcInf.append(txt)\n",
    "    docsInfo.append(dcInf)\n",
    "df = pd.DataFrame(docsInfo, columns=docFeats)\n",
    "df[\"labelDict\"] = \"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>filename</th>\n",
       "      <th>text</th>\n",
       "      <th>labelDict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data/development-docs</td>\n",
       "      <td>10042</td>\n",
       "      <td>Meridian Energy Inc and CastoneDevelopment Cor...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>data/development-docs</td>\n",
       "      <td>10066</td>\n",
       "      <td>Security Pacific Corp andUsers Inc, a credit u...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>data/development-docs</td>\n",
       "      <td>10158</td>\n",
       "      <td>Americanture Inc said it haspurchased American...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>data/development-docs</td>\n",
       "      <td>10171</td>\n",
       "      <td>Viacom International Inc said it setApril 6 as...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>data/development-docs</td>\n",
       "      <td>1029</td>\n",
       "      <td>Scott's Hospitality Inc said itacquired all is...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>data/development-docs</td>\n",
       "      <td>9733</td>\n",
       "      <td>British Petroleum Co Plc  said itintended to m...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>data/development-docs</td>\n",
       "      <td>9809</td>\n",
       "      <td>Mickelberry Corp said it has completedthe prev...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>data/development-docs</td>\n",
       "      <td>982</td>\n",
       "      <td>H.J. Heinz  chairman Tony O'Reillywould be int...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>data/development-docs</td>\n",
       "      <td>9858</td>\n",
       "      <td>MCO Holdings Inc said itsshareholders and thos...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>data/development-docs</td>\n",
       "      <td>9893</td>\n",
       "      <td>Cross and Trecker said itagreed to acquire the...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>398 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      path filename  \\\n",
       "0    data/development-docs    10042   \n",
       "1    data/development-docs    10066   \n",
       "2    data/development-docs    10158   \n",
       "3    data/development-docs    10171   \n",
       "4    data/development-docs     1029   \n",
       "..                     ...      ...   \n",
       "393  data/development-docs     9733   \n",
       "394  data/development-docs     9809   \n",
       "395  data/development-docs      982   \n",
       "396  data/development-docs     9858   \n",
       "397  data/development-docs     9893   \n",
       "\n",
       "                                                  text labelDict  \n",
       "0    Meridian Energy Inc and CastoneDevelopment Cor...            \n",
       "1    Security Pacific Corp andUsers Inc, a credit u...            \n",
       "2    Americanture Inc said it haspurchased American...            \n",
       "3    Viacom International Inc said it setApril 6 as...            \n",
       "4    Scott's Hospitality Inc said itacquired all is...            \n",
       "..                                                 ...       ...  \n",
       "393  British Petroleum Co Plc  said itintended to m...            \n",
       "394  Mickelberry Corp said it has completedthe prev...            \n",
       "395  H.J. Heinz  chairman Tony O'Reillywould be int...            \n",
       "396  MCO Holdings Inc said itsshareholders and thos...            \n",
       "397  Cross and Trecker said itagreed to acquire the...            \n",
       "\n",
       "[398 rows x 4 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###Try linear regressor, multilabel with 7 labels\n",
    "## use features from last project except vectorized (contextual vect hopefully) + doc number?\n",
    "## words, POS tags, dependency relations, NER classes, semantic categories, and a context window- vectorized doc. \n",
    "## one hot encode output vector and sigmoid it\n",
    "\n",
    "## train on corpus\n",
    "# df.loc[df['filename'] == keyName.replace(\".key\", \"\"), 'labelDict'] = dic\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Labels\n",
    "\n",
    "Creates a an array dictionaries of {wd:label}\n",
    "\n",
    "One array for each key file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "outps = ['-', 'B-AQ', 'I-AQ', 'B-AQB', 'I-AQB', 'B-AQL', 'I-AQL', 'B-AMT', 'I-AMT', 'B-PURCH', 'I-PURCH', 'B-SELL', 'I-SELL', 'B-STAT', 'I-STAT']\n",
    "cats = ['TXT','AQ', 'AQB', 'AQL', 'AMT', 'PURCH', 'SELL', 'STAT']\n",
    "#Creaetes dictionary of wd:label\n",
    "##TODO: go through and add to data\n",
    "\n",
    "# Get list of paths\n",
    "keyFolder = 'data/development-anskeys'\n",
    "keyNames = os.listdir(keyFolder)\n",
    "allDics = {}\n",
    "for keyName in keyNames:\n",
    "    dic = {}\n",
    "    with open(os.path.join(keyFolder, keyName), 'r') as f:\n",
    "        i = 0\n",
    "        for l in f.readlines():\n",
    "            wds = l.split()\n",
    "            if i != 0:\n",
    "                for j in range(len(wds)):\n",
    "                    if j == 1: #beginning of phrase\n",
    "                        pref = \"B-\"\n",
    "                    else: #middle of phrase\n",
    "                        pref = \"I-\"\n",
    "                    if j != 0 and i < len(cats):\n",
    "                        post = cats[i]\n",
    "                        dic[wds[j].replace(\"\\\"\", \"\")] = pref+post\n",
    "            i+= 1\n",
    "    allDics[keyName.replace(\".key\", \"\")] = (dic)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Data\n",
    "\n",
    "Creates list of feature vectors (per word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31244, 15)\n",
      "(7938, 15)\n",
      "['B-PURCH', 0, 1, 0, 'PROPN', 'PROPN', 'PHIPOS', 0, 0, 'Meridian', 'Energy', 'PHI', 'NNP', 'NNP', 'PHITAG']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "#TODO: convert wds to embeddings and add context embedding. Also one hot label\n",
    "\n",
    "# Create data\n",
    "features = [\"LABEL\", \"ABBR\",\"CAP\",\"LOC\",\"POS\",\"POS+1\",\"POS-1\",\"PREF\",\"SUFF\",\"WORD\",\"WORD+1\",\"WORD-1\",\"TAG\",\"TAG+1\",\"TAG-1\"]\n",
    "\n",
    "trainData = []\n",
    "testData = []\n",
    "#split into sentences\n",
    "for text, filename in zip(df['text'].values, df['filename'].values):\n",
    "    doc = nlp(text)\n",
    "    sentences = [sent.text.strip() for sent in doc.sents]\n",
    "    test = False\n",
    "    if random.random() <= 0.20: #put about 20& of articles in test set\n",
    "        test = True\n",
    "    for s in sentences:\n",
    "        if test:\n",
    "            testData += extractFeatures(s, allDics[filename])\n",
    "        else:\n",
    "            trainData += extractFeatures(s, allDics[filename])\n",
    "\n",
    "\n",
    "print(np.shape(trainData))\n",
    "print(np.shape(testData))\n",
    "print(trainData[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDf = pd.DataFrame(trainData, columns=features)\n",
    "trainDf.to_csv(\"trainData.csv\", index=False)\n",
    "\n",
    "testDf = pd.DataFrame(testData, columns=features)\n",
    "testDf.to_csv(\"testData.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run model trained on ^^ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8733938019652305\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from ml import vectorize_data, read_csv_for_ml, logistic\n",
    "\n",
    "#For word in testData\n",
    "dictvect = joblib.load(\"dicVec.joblib\")\n",
    "vect_test = dictvect.transform(testDf.to_dict('records'))\n",
    "\n",
    "loaded_model = pickle.load(open('logistic_regression_model.joblib', 'rb'))\n",
    "\n",
    "result = loaded_model.score(vect_test, test_labels)\n",
    "print(result)\n",
    "\n",
    "#save to dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B-PURCH [{'CAP': 1.0, 'POS+1=PROPN': 1.0, 'POS-1=PHIPOS': 1.0, 'POS=PROPN': 1.0, 'TAG+1=NNP': 1.0, 'TAG-1=PHITAG': 1.0, 'TAG=NNP': 1.0, 'WORD+1=Pacific': 1.0, 'WORD-1=PHI': 1.0, 'WORD=Security': 1.0}] ['B-PURCH', 0, 1, 0, 'PROPN', 'PROPN', 'PHIPOS', 0, 0, 'Security', 'Pacific', 'PHI', 'NNP', 'NNP', 'PHITAG']\n"
     ]
    }
   ],
   "source": [
    "dictvect = joblib.load(\"dicVec.joblib\")\n",
    "loaded_model = pickle.load(open('logistic_regression_model.joblib', 'rb'))\n",
    "\n",
    "ind = 0\n",
    "\n",
    "X = testDf.drop('LABEL', axis=1)\n",
    "test_vect = dictvect.transform(X.to_dict(\"records\"))\n",
    "pred = loaded_model.predict(vect_test)\n",
    "print(pred[ind], dictvect.inverse_transform([vect_test[ind]]), testData[ind])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "doclisttxt = 'doclist.txt'\n",
    "\n",
    "#constants\n",
    "dictvect = joblib.load(\"dicVec.joblib\")\n",
    "loaded_model = pickle.load(open('logistic_regression_model.joblib', 'rb'))\n",
    "features = [\"LABEL\", \"ABBR\",\"CAP\",\"LOC\",\"POS\",\"POS+1\",\"POS-1\",\"PREF\",\"SUFF\",\"WORD\",\"WORD+1\",\"WORD-1\",\"TAG\",\"TAG+1\",\"TAG-1\"]\n",
    "\n",
    "## Add all docs to dataframe\n",
    "docFeats = [\"path\", \"filename\", \"text\"]\n",
    "doclist = open(doclisttxt, 'r')\n",
    "docsInfo = []\n",
    "for doc in doclist.readlines():\n",
    "    dcInf = []\n",
    "    pcs = doc.strip().split(\"/\")\n",
    "    dcInf.append(\"/\".join(pcs[0:-1]))\n",
    "    dcInf.append(pcs[-1])\n",
    "    with open(doc.strip()) as txtFile:\n",
    "        txt = \"\"\n",
    "        for l in txtFile.readlines():\n",
    "            txt += (\" \" + l.strip())\n",
    "        dcInf.append(txt.strip())\n",
    "    docsInfo.append(dcInf)\n",
    "df = pd.DataFrame(docsInfo, columns=docFeats)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10042 Meridian Energy Inc and Castone Development Corp, a privately-held company, jointly announced that they have decided to terminate the letter of intent under which Meridian would have acquired Castone.\n",
      "featdf (29, 14)\n",
      "TXT: 10042\n",
      "AQ: \n",
      "AQB: \n",
      "AQL: \n",
      "AMT: \n",
      "PURCH: Inc\n",
      "SELL: \n",
      "STAT: of intent\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## iterate through text and perform interence\n",
    "for text, filename in zip(df['text'].values, df['filename'].values):\n",
    "    print(filename, text)\n",
    "    outpDict = {'TXT': [filename] ,'AQ': [], 'AQB': [], 'AQL': [], 'AMT': [], 'PURCH': [], 'SELL': [], 'STAT': []}\n",
    "    \n",
    "    #extract features from text\n",
    "    doc = nlp(text)\n",
    "    sentences = [sent.text.strip() for sent in doc.sents]\n",
    "    data = []\n",
    "    for s in sentences:\n",
    "        data += extractFeatures(s, '-') #allDics[filename])\n",
    "    data = np.array(data)\n",
    "\n",
    "    #perform interence\n",
    "    featDf = pd.DataFrame(data, columns=features)\n",
    "    X = featDf.drop('LABEL', axis=1)\n",
    "    print(\"featdf\", X.shape)\n",
    "    test_vect = dictvect.transform(X.to_dict(\"records\"))\n",
    "    pred = loaded_model.predict(test_vect)\n",
    "\n",
    "    #Read through predictions add to dict\n",
    "    for idx, p in enumerate(pred):\n",
    "        postf = p.split(\"-\")[-1]\n",
    "        if postf in outpDict:\n",
    "            outpDict[postf].append(X.iloc[idx]['WORD'])\n",
    "        #else ignore it, probably a -\n",
    "\n",
    "    #stringify predictions dict and add to dataframe? or just print to file\n",
    "    outStr = \"\"\n",
    "    for lab in outpDict.keys():\n",
    "        outStr += (lab + \": \\\"\")\n",
    "        outStr += \" \".join([wd for wd in outpDict[lab]])\n",
    "        outStr += \"\\\"\\n\"\n",
    "    print(outStr)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function dict.keys>"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outpDict.keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ABBR</th>\n",
       "      <th>CAP</th>\n",
       "      <th>LOC</th>\n",
       "      <th>POS</th>\n",
       "      <th>POS+1</th>\n",
       "      <th>POS-1</th>\n",
       "      <th>PREF</th>\n",
       "      <th>SUFF</th>\n",
       "      <th>WORD</th>\n",
       "      <th>WORD+1</th>\n",
       "      <th>WORD-1</th>\n",
       "      <th>TAG</th>\n",
       "      <th>TAG+1</th>\n",
       "      <th>TAG-1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>PHIPOS</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Gulf</td>\n",
       "      <td>Applied</td>\n",
       "      <td>PHI</td>\n",
       "      <td>NNP</td>\n",
       "      <td>NNP</td>\n",
       "      <td>PHITAG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Applied</td>\n",
       "      <td>Technologies</td>\n",
       "      <td>Gulf</td>\n",
       "      <td>NNP</td>\n",
       "      <td>NNPS</td>\n",
       "      <td>NNP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Technologies</td>\n",
       "      <td>Inc</td>\n",
       "      <td>Applied</td>\n",
       "      <td>NNPS</td>\n",
       "      <td>NNP</td>\n",
       "      <td>NNP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>VERB</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Inc</td>\n",
       "      <td>said</td>\n",
       "      <td>Technologies</td>\n",
       "      <td>NNP</td>\n",
       "      <td>VBD</td>\n",
       "      <td>NNPS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>VERB</td>\n",
       "      <td>PRON</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>said</td>\n",
       "      <td>it</td>\n",
       "      <td>Inc</td>\n",
       "      <td>VBD</td>\n",
       "      <td>PRP</td>\n",
       "      <td>NNP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>PRON</td>\n",
       "      <td>VERB</td>\n",
       "      <td>VERB</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>it</td>\n",
       "      <td>sold</td>\n",
       "      <td>said</td>\n",
       "      <td>PRP</td>\n",
       "      <td>VBD</td>\n",
       "      <td>VBD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>VERB</td>\n",
       "      <td>PRON</td>\n",
       "      <td>PRON</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>sold</td>\n",
       "      <td>its</td>\n",
       "      <td>it</td>\n",
       "      <td>VBD</td>\n",
       "      <td>PRP$</td>\n",
       "      <td>PRP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>PRON</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>VERB</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>its</td>\n",
       "      <td>subsidiaries</td>\n",
       "      <td>sold</td>\n",
       "      <td>PRP$</td>\n",
       "      <td>NNS</td>\n",
       "      <td>VBD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>VERB</td>\n",
       "      <td>PRON</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>subsidiaries</td>\n",
       "      <td>engaged</td>\n",
       "      <td>its</td>\n",
       "      <td>NNS</td>\n",
       "      <td>VBN</td>\n",
       "      <td>PRP$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>VERB</td>\n",
       "      <td>ADP</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>engaged</td>\n",
       "      <td>in</td>\n",
       "      <td>subsidiaries</td>\n",
       "      <td>VBN</td>\n",
       "      <td>IN</td>\n",
       "      <td>NNS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>ADP</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>VERB</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>in</td>\n",
       "      <td>pipeline</td>\n",
       "      <td>engaged</td>\n",
       "      <td>IN</td>\n",
       "      <td>NN</td>\n",
       "      <td>VBN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>CCONJ</td>\n",
       "      <td>ADP</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>pipeline</td>\n",
       "      <td>and</td>\n",
       "      <td>in</td>\n",
       "      <td>NN</td>\n",
       "      <td>CC</td>\n",
       "      <td>IN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>CCONJ</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>and</td>\n",
       "      <td>terminal</td>\n",
       "      <td>pipeline</td>\n",
       "      <td>CC</td>\n",
       "      <td>JJ</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>CCONJ</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>terminal</td>\n",
       "      <td>operations</td>\n",
       "      <td>and</td>\n",
       "      <td>JJ</td>\n",
       "      <td>NNS</td>\n",
       "      <td>CC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>ADP</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>operations</td>\n",
       "      <td>for</td>\n",
       "      <td>terminal</td>\n",
       "      <td>NNS</td>\n",
       "      <td>IN</td>\n",
       "      <td>JJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>ADP</td>\n",
       "      <td>NUM</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>for</td>\n",
       "      <td>12.2</td>\n",
       "      <td>operations</td>\n",
       "      <td>IN</td>\n",
       "      <td>CD</td>\n",
       "      <td>NNS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NUM</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>ADP</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12.2</td>\n",
       "      <td>mln</td>\n",
       "      <td>for</td>\n",
       "      <td>CD</td>\n",
       "      <td>NN</td>\n",
       "      <td>IN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NUM</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>mln</td>\n",
       "      <td>dlrs.</td>\n",
       "      <td>12.2</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>CD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>OMEGAPOS</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>dlrs.</td>\n",
       "      <td>OMEGA</td>\n",
       "      <td>mln</td>\n",
       "      <td>NN</td>\n",
       "      <td>OMEGATAG</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>DET</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>PHIPOS</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>The</td>\n",
       "      <td>company</td>\n",
       "      <td>PHI</td>\n",
       "      <td>DT</td>\n",
       "      <td>NN</td>\n",
       "      <td>PHITAG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>VERB</td>\n",
       "      <td>DET</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>company</td>\n",
       "      <td>said</td>\n",
       "      <td>The</td>\n",
       "      <td>NN</td>\n",
       "      <td>VBD</td>\n",
       "      <td>DT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>VERB</td>\n",
       "      <td>DET</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>said</td>\n",
       "      <td>the</td>\n",
       "      <td>company</td>\n",
       "      <td>VBD</td>\n",
       "      <td>DT</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>DET</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>VERB</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>the</td>\n",
       "      <td>sale</td>\n",
       "      <td>said</td>\n",
       "      <td>DT</td>\n",
       "      <td>NN</td>\n",
       "      <td>VBD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>AUX</td>\n",
       "      <td>DET</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>sale</td>\n",
       "      <td>is</td>\n",
       "      <td>the</td>\n",
       "      <td>NN</td>\n",
       "      <td>VBZ</td>\n",
       "      <td>DT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>AUX</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>is</td>\n",
       "      <td>subject</td>\n",
       "      <td>sale</td>\n",
       "      <td>VBZ</td>\n",
       "      <td>JJ</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>ADP</td>\n",
       "      <td>AUX</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>subject</td>\n",
       "      <td>to</td>\n",
       "      <td>is</td>\n",
       "      <td>JJ</td>\n",
       "      <td>IN</td>\n",
       "      <td>VBZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>ADP</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>to</td>\n",
       "      <td>certain</td>\n",
       "      <td>subject</td>\n",
       "      <td>IN</td>\n",
       "      <td>JJ</td>\n",
       "      <td>JJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>ADP</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>certain</td>\n",
       "      <td>post</td>\n",
       "      <td>to</td>\n",
       "      <td>JJ</td>\n",
       "      <td>NN</td>\n",
       "      <td>IN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>post</td>\n",
       "      <td>closing</td>\n",
       "      <td>certain</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>JJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>closing</td>\n",
       "      <td>adjustments,</td>\n",
       "      <td>post</td>\n",
       "      <td>NN</td>\n",
       "      <td>NNS</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>adjustments,</td>\n",
       "      <td>which</td>\n",
       "      <td>closing</td>\n",
       "      <td>NNS</td>\n",
       "      <td>,</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>DET</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>which</td>\n",
       "      <td>it</td>\n",
       "      <td>adjustments,</td>\n",
       "      <td>,</td>\n",
       "      <td>WDT</td>\n",
       "      <td>NNS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>DET</td>\n",
       "      <td>PRON</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>it</td>\n",
       "      <td>did</td>\n",
       "      <td>which</td>\n",
       "      <td>WDT</td>\n",
       "      <td>PRP</td>\n",
       "      <td>,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>PRON</td>\n",
       "      <td>AUX</td>\n",
       "      <td>DET</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>did</td>\n",
       "      <td>not</td>\n",
       "      <td>it</td>\n",
       "      <td>PRP</td>\n",
       "      <td>VBD</td>\n",
       "      <td>WDT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>AUX</td>\n",
       "      <td>PART</td>\n",
       "      <td>PRON</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>not</td>\n",
       "      <td>explain.</td>\n",
       "      <td>did</td>\n",
       "      <td>VBD</td>\n",
       "      <td>RB</td>\n",
       "      <td>PRP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>PART</td>\n",
       "      <td>OMEGAPOS</td>\n",
       "      <td>AUX</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>explain.</td>\n",
       "      <td>OMEGA</td>\n",
       "      <td>not</td>\n",
       "      <td>RB</td>\n",
       "      <td>OMEGATAG</td>\n",
       "      <td>VBD</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ABBR CAP LOC    POS     POS+1   POS-1 PREF SUFF          WORD  \\\n",
       "0     0   1   0  PROPN     PROPN  PHIPOS    0    0          Gulf   \n",
       "1     0   1   0  PROPN     PROPN   PROPN    0    0       Applied   \n",
       "2     0   1   0  PROPN     PROPN   PROPN    0    1  Technologies   \n",
       "3     0   1   0  PROPN      VERB   PROPN    0    0           Inc   \n",
       "4     0   0   0   VERB      PRON   PROPN    0    0          said   \n",
       "5     0   0   0   PRON      VERB    VERB    0    0            it   \n",
       "6     0   0   0   VERB      PRON    PRON    0    0          sold   \n",
       "7     0   0   0   PRON      NOUN    VERB    0    0           its   \n",
       "8     0   0   0   NOUN      VERB    PRON    0    0  subsidiaries   \n",
       "9     0   0   0   VERB       ADP    NOUN    0    0       engaged   \n",
       "10    0   0   0    ADP      NOUN    VERB    0    0            in   \n",
       "11    0   0   0   NOUN     CCONJ     ADP    0    0      pipeline   \n",
       "12    0   0   0  CCONJ       ADJ    NOUN    0    0           and   \n",
       "13    0   0   0    ADJ      NOUN   CCONJ    0    0      terminal   \n",
       "14    0   0   0   NOUN       ADP     ADJ    0    0    operations   \n",
       "15    0   0   0    ADP       NUM    NOUN    0    0           for   \n",
       "16    0   0   0    NUM      NOUN     ADP    0    0          12.2   \n",
       "17    0   0   0   NOUN      NOUN     NUM    0    0           mln   \n",
       "18    0   0   0   NOUN  OMEGAPOS    NOUN    0    0         dlrs.   \n",
       "19    0   1   0    DET      NOUN  PHIPOS    0    0           The   \n",
       "20    0   0   0   NOUN      VERB     DET    0    0       company   \n",
       "21    0   0   0   VERB       DET    NOUN    0    0          said   \n",
       "22    0   0   0    DET      NOUN    VERB    0    0           the   \n",
       "23    0   0   0   NOUN       AUX     DET    0    0          sale   \n",
       "24    0   0   0    AUX       ADJ    NOUN    0    0            is   \n",
       "25    0   0   0    ADJ       ADP     AUX    0    0       subject   \n",
       "26    0   0   0    ADP       ADJ     ADJ    0    0            to   \n",
       "27    0   0   0    ADJ      NOUN     ADP    0    0       certain   \n",
       "28    0   0   0   NOUN      NOUN     ADJ    0    0          post   \n",
       "29    0   0   0   NOUN      NOUN    NOUN    0    0       closing   \n",
       "30    0   0   0   NOUN     PUNCT    NOUN    0    0  adjustments,   \n",
       "31    0   0   0  PUNCT       DET    NOUN    0    0         which   \n",
       "32    0   0   0    DET      PRON   PUNCT    0    0            it   \n",
       "33    0   0   0   PRON       AUX     DET    0    0           did   \n",
       "34    0   0   0    AUX      PART    PRON    0    0           not   \n",
       "35    0   0   0   PART  OMEGAPOS     AUX    0    0      explain.   \n",
       "\n",
       "          WORD+1        WORD-1   TAG     TAG+1   TAG-1  \n",
       "0        Applied           PHI   NNP       NNP  PHITAG  \n",
       "1   Technologies          Gulf   NNP      NNPS     NNP  \n",
       "2            Inc       Applied  NNPS       NNP     NNP  \n",
       "3           said  Technologies   NNP       VBD    NNPS  \n",
       "4             it           Inc   VBD       PRP     NNP  \n",
       "5           sold          said   PRP       VBD     VBD  \n",
       "6            its            it   VBD      PRP$     PRP  \n",
       "7   subsidiaries          sold  PRP$       NNS     VBD  \n",
       "8        engaged           its   NNS       VBN    PRP$  \n",
       "9             in  subsidiaries   VBN        IN     NNS  \n",
       "10      pipeline       engaged    IN        NN     VBN  \n",
       "11           and            in    NN        CC      IN  \n",
       "12      terminal      pipeline    CC        JJ      NN  \n",
       "13    operations           and    JJ       NNS      CC  \n",
       "14           for      terminal   NNS        IN      JJ  \n",
       "15          12.2    operations    IN        CD     NNS  \n",
       "16           mln           for    CD        NN      IN  \n",
       "17         dlrs.          12.2    NN        NN      CD  \n",
       "18         OMEGA           mln    NN  OMEGATAG      NN  \n",
       "19       company           PHI    DT        NN  PHITAG  \n",
       "20          said           The    NN       VBD      DT  \n",
       "21           the       company   VBD        DT      NN  \n",
       "22          sale          said    DT        NN     VBD  \n",
       "23            is           the    NN       VBZ      DT  \n",
       "24       subject          sale   VBZ        JJ      NN  \n",
       "25            to            is    JJ        IN     VBZ  \n",
       "26       certain       subject    IN        JJ      JJ  \n",
       "27          post            to    JJ        NN      IN  \n",
       "28       closing       certain    NN        NN      JJ  \n",
       "29  adjustments,          post    NN       NNS      NN  \n",
       "30         which       closing   NNS         ,      NN  \n",
       "31            it  adjustments,     ,       WDT     NNS  \n",
       "32           did         which   WDT       PRP       ,  \n",
       "33           not            it   PRP       VBD     WDT  \n",
       "34      explain.           did   VBD        RB     PRP  \n",
       "35         OMEGA           not    RB  OMEGATAG     VBD  "
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "featDf"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8ca4ed7e0411efdd55c86abb9501ed3ebc25f575cccb7f83736f13ee17cb9622"
  },
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
